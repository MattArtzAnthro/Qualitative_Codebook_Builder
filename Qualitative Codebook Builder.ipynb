{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated Codebook Development from Source Documents\n",
        "\n",
        "Created by [**Matt Artz**](https://www.mattartz.me/) — advancing computational approaches in anthropology.\n",
        "\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook implements a system for extracting and developing research codebooks from source materials (academic articles, reports, methodology guides) following established methodological best practices. The system extracts theoretical constructs, methodological approaches, and key concepts to build a codebook suitable for peer review.\n",
        "\n",
        "Designed with techno-anthropology in mind, this tool supports researchers aiming to incorporate computational methods into their qualitative workflows while retaining human interpretive oversight.\n",
        "\n",
        "## Key Features\n",
        "\n",
        "1. **Comprehensive File Support**: PDF, DOCX, DOC, TXT, RTF, XLSX, CSV\n",
        "2. **Best Practice Implementation**: Following methodological literature for codebook development\n",
        "3. **Extraction Strategies**: Inductive, deductive, and hybrid coding approaches\n",
        "4. **Quality Assurance**: Automated validation and conceptual distinctness assessment\n",
        "5. **Version Control**: Full semantic versioning with changelog\n",
        "6. **Multiple Export Formats**: CSV, JSON, Markdown, ATLAS.ti, NVivo compatible\n",
        "\n",
        "## Workflow\n",
        "\n",
        "1. Upload source documents (academic articles, reports, etc.)\n",
        "2. System analyzes document types and content\n",
        "3. Extracts potential codes based on chosen strategy\n",
        "4. Refines codes through similarity detection and validation\n",
        "5. Exports codebook in multiple formats with full documentation\n",
        "\n",
        "## Important Notes\n",
        "\n",
        "- This system extracts codes FROM documents, not applying codes TO data\n",
        "- Maximum 40 initial codes to prevent cognitive overload\n",
        "- All codes include definitions, criteria, and examples\n",
        "- Suitable for academic peer review and publication\n",
        "\n",
        "## License\n",
        "\n",
        "This project is licensed under the **Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)** license. You may remix, adapt, and build upon the material for non-commercial purposes, provided you credit *Matt Artz* and link to the repository.  \n",
        "Full details: [https://creativecommons.org/licenses/by-nc/4.0/](https://creativecommons.org/licenses/by-nc/4.0/)\n",
        "\n",
        "## Citation\n",
        "\n",
        "If you use this in your work, please cite:\n",
        "\n",
        "> Artz, Matt. 2025. *Qualitative Codebook Builder*. Software. Zenodo. https://doi.org/10.5281/zenodo.15808613.\n",
        "\n"
      ],
      "metadata": {
        "id": "6IK6WsT4-YXC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup and Package Installation\n"
      ],
      "metadata": {
        "id": "F1a9fC-MS5Ls"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgihSTfVS3Wk"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install anthropic pandas numpy scikit-learn nltk PyPDF2 python-docx openpyxl\n",
        "!pip install sentence-transformers python-pptx striprtf\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "import anthropic\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "import time\n",
        "from IPython.display import display, HTML\n",
        "import ipywidgets as widgets\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# NLP and text processing\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')  # Add this to fix potential NLTK issues\n",
        "\n",
        "# File handling\n",
        "import PyPDF2\n",
        "from docx import Document\n",
        "from striprtf.striprtf import rtf_to_text\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "\n",
        "# For semantic similarity in code refinement\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Version control\n",
        "import hashlib\n",
        "from copy import deepcopy\n",
        "\n",
        "print(\"✓ All packages installed successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration and Codebook Structure"
      ],
      "metadata": {
        "id": "81CKSGIkioo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Interactive Configuration System with Widgets\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "import anthropic\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Configuration following best practices from methodological literature\"\"\"\n",
        "    # Default values\n",
        "    ANTHROPIC_API_KEY = \"\"\n",
        "    MAX_CODE_LABEL_LENGTH = 25\n",
        "    MIN_DEFINITION_LENGTH = 20\n",
        "    MAX_INITIAL_CODES = 40\n",
        "    MIN_EXAMPLES_PER_CODE = 2\n",
        "    MIN_CODE_FREQUENCY = 2\n",
        "    SIMILARITY_THRESHOLD = 0.85\n",
        "    CHUNK_SIZE = 500\n",
        "    OVERLAP = 50\n",
        "    MODEL = \"claude-sonnet-4-20250514\"\n",
        "    MAX_TOKENS = 4000\n",
        "    TEMPERATURE = 0.3\n",
        "    OUTPUT_PATH = \"/content/codebook_outputs/\"\n",
        "    VERSION_PATH = \"/content/codebook_versions/\"\n",
        "    PURPOSE = \"Extract theoretical and methodological codes from academic literature\"\n",
        "    EPISTEMOLOGICAL_STANCE = \"pragmatic\"\n",
        "    CODING_STRATEGY = \"hybrid\"\n",
        "\n",
        "def create_configuration_interface():\n",
        "    \"\"\"Create interactive configuration interface\"\"\"\n",
        "\n",
        "    # Styling\n",
        "    style = {'description_width': '200px'}\n",
        "    layout = widgets.Layout(width='400px')\n",
        "\n",
        "    print(\"=== Codebook Configuration Interface ===\")\n",
        "    print(\"Configure your codebook development parameters below:\")\n",
        "\n",
        "    # API Configuration\n",
        "    api_header = widgets.HTML(\"<h3>🔑 API Configuration</h3>\")\n",
        "\n",
        "    api_key_widget = widgets.Password(\n",
        "        value=Config.ANTHROPIC_API_KEY,\n",
        "        placeholder='Enter your Anthropic API key',\n",
        "        description='Anthropic API Key:',\n",
        "        style=style,\n",
        "        layout=layout\n",
        "    )\n",
        "\n",
        "    model_widget = widgets.Dropdown(\n",
        "        options=[\n",
        "            'claude-sonnet-4-20250514',\n",
        "            'claude-3-5-sonnet-20241022',\n",
        "        ],\n",
        "        value=Config.MODEL,\n",
        "        description='Claude Model:',\n",
        "        style=style,\n",
        "        layout=layout\n",
        "    )\n",
        "\n",
        "    # Codebook Parameters\n",
        "    codebook_header = widgets.HTML(\"<h3>📚 Codebook Parameters</h3>\")\n",
        "\n",
        "    max_codes_widget = widgets.IntSlider(\n",
        "        value=Config.MAX_INITIAL_CODES,\n",
        "        min=10,\n",
        "        max=100,\n",
        "        step=5,\n",
        "        description='Max Initial Codes:',\n",
        "        style=style,\n",
        "        layout=layout\n",
        "    )\n",
        "\n",
        "    max_label_length_widget = widgets.IntSlider(\n",
        "        value=Config.MAX_CODE_LABEL_LENGTH,\n",
        "        min=15,\n",
        "        max=50,\n",
        "        step=5,\n",
        "        description='Max Label Length:',\n",
        "        style=style,\n",
        "        layout=layout\n",
        "    )\n",
        "\n",
        "    min_definition_length_widget = widgets.IntSlider(\n",
        "        value=Config.MIN_DEFINITION_LENGTH,\n",
        "        min=10,\n",
        "        max=100,\n",
        "        step=5,\n",
        "        description='Min Definition Length:',\n",
        "        style=style,\n",
        "        layout=layout\n",
        "    )\n",
        "\n",
        "    min_examples_widget = widgets.IntSlider(\n",
        "        value=Config.MIN_EXAMPLES_PER_CODE,\n",
        "        min=1,\n",
        "        max=5,\n",
        "        step=1,\n",
        "        description='Min Examples per Code:',\n",
        "        style=style,\n",
        "        layout=layout\n",
        "    )\n",
        "\n",
        "    # Quality Thresholds\n",
        "    quality_header = widgets.HTML(\"<h3>🎯 Quality Thresholds</h3>\")\n",
        "\n",
        "    min_frequency_widget = widgets.IntSlider(\n",
        "        value=Config.MIN_CODE_FREQUENCY,\n",
        "        min=1,\n",
        "        max=10,\n",
        "        step=1,\n",
        "        description='Min Code Frequency:',\n",
        "        style=style,\n",
        "        layout=layout\n",
        "    )\n",
        "\n",
        "    similarity_threshold_widget = widgets.FloatSlider(\n",
        "        value=Config.SIMILARITY_THRESHOLD,\n",
        "        min=0.5,\n",
        "        max=0.95,\n",
        "        step=0.05,\n",
        "        description='Similarity Threshold:',\n",
        "        style=style,\n",
        "        layout=layout\n",
        "    )\n",
        "\n",
        "    # Processing Parameters\n",
        "    processing_header = widgets.HTML(\"<h3>⚙️ Processing Parameters</h3>\")\n",
        "\n",
        "    chunk_size_widget = widgets.IntSlider(\n",
        "        value=Config.CHUNK_SIZE,\n",
        "        min=200,\n",
        "        max=1000,\n",
        "        step=50,\n",
        "        description='Chunk Size (words):',\n",
        "        style=style,\n",
        "        layout=layout\n",
        "    )\n",
        "\n",
        "    overlap_widget = widgets.IntSlider(\n",
        "        value=Config.OVERLAP,\n",
        "        min=10,\n",
        "        max=200,\n",
        "        step=10,\n",
        "        description='Chunk Overlap:',\n",
        "        style=style,\n",
        "        layout=layout\n",
        "    )\n",
        "\n",
        "    # LLM Parameters\n",
        "    llm_header = widgets.HTML(\"<h3>🤖 LLM Parameters</h3>\")\n",
        "\n",
        "    max_tokens_widget = widgets.IntSlider(\n",
        "        value=Config.MAX_TOKENS,\n",
        "        min=1000,\n",
        "        max=8000,\n",
        "        step=500,\n",
        "        description='Max Tokens:',\n",
        "        style=style,\n",
        "        layout=layout\n",
        "    )\n",
        "\n",
        "    temperature_widget = widgets.FloatSlider(\n",
        "        value=Config.TEMPERATURE,\n",
        "        min=0.0,\n",
        "        max=1.0,\n",
        "        step=0.1,\n",
        "        description='Temperature:',\n",
        "        style=style,\n",
        "        layout=layout\n",
        "    )\n",
        "\n",
        "    # Research Configuration\n",
        "    research_header = widgets.HTML(\"<h3>🔬 Research Configuration</h3>\")\n",
        "\n",
        "    purpose_widget = widgets.Textarea(\n",
        "        value=Config.PURPOSE,\n",
        "        placeholder='Describe the purpose of your codebook...',\n",
        "        description='Codebook Purpose:',\n",
        "        style=style,\n",
        "        layout=widgets.Layout(width='600px', height='80px')\n",
        "    )\n",
        "\n",
        "    epistemological_widget = widgets.Dropdown(\n",
        "        options=['positivist', 'interpretivist', 'critical', 'pragmatic'],\n",
        "        value=Config.EPISTEMOLOGICAL_STANCE,\n",
        "        description='Epistemological Stance:',\n",
        "        style=style,\n",
        "        layout=layout\n",
        "    )\n",
        "\n",
        "    coding_strategy_widget = widgets.Dropdown(\n",
        "        options=['deductive', 'inductive', 'hybrid'],\n",
        "        value=Config.CODING_STRATEGY,\n",
        "        description='Coding Strategy:',\n",
        "        style=style,\n",
        "        layout=layout\n",
        "    )\n",
        "\n",
        "    # Action Buttons\n",
        "    button_layout = widgets.Layout(width='150px', margin='10px')\n",
        "\n",
        "    apply_button = widgets.Button(\n",
        "        description='Apply Configuration',\n",
        "        button_style='success',\n",
        "        layout=button_layout,\n",
        "        icon='check'\n",
        "    )\n",
        "\n",
        "    test_api_button = widgets.Button(\n",
        "        description='Test API Key',\n",
        "        button_style='info',\n",
        "        layout=button_layout,\n",
        "        icon='key'\n",
        "    )\n",
        "\n",
        "    reset_button = widgets.Button(\n",
        "        description='Reset to Defaults',\n",
        "        button_style='warning',\n",
        "        layout=button_layout,\n",
        "        icon='refresh'\n",
        "    )\n",
        "\n",
        "    # Status output\n",
        "    status_output = widgets.Output()\n",
        "\n",
        "    # Event handlers\n",
        "    def apply_configuration(b):\n",
        "        with status_output:\n",
        "            status_output.clear_output()\n",
        "            try:\n",
        "                # Update Config class\n",
        "                Config.ANTHROPIC_API_KEY = api_key_widget.value\n",
        "                Config.MODEL = model_widget.value\n",
        "                Config.MAX_INITIAL_CODES = max_codes_widget.value\n",
        "                Config.MAX_CODE_LABEL_LENGTH = max_label_length_widget.value\n",
        "                Config.MIN_DEFINITION_LENGTH = min_definition_length_widget.value\n",
        "                Config.MIN_EXAMPLES_PER_CODE = min_examples_widget.value\n",
        "                Config.MIN_CODE_FREQUENCY = min_frequency_widget.value\n",
        "                Config.SIMILARITY_THRESHOLD = similarity_threshold_widget.value\n",
        "                Config.CHUNK_SIZE = chunk_size_widget.value\n",
        "                Config.OVERLAP = overlap_widget.value\n",
        "                Config.MAX_TOKENS = max_tokens_widget.value\n",
        "                Config.TEMPERATURE = temperature_widget.value\n",
        "                Config.PURPOSE = purpose_widget.value\n",
        "                Config.EPISTEMOLOGICAL_STANCE = epistemological_widget.value\n",
        "                Config.CODING_STRATEGY = coding_strategy_widget.value\n",
        "\n",
        "                # Initialize client\n",
        "                global client\n",
        "                client = anthropic.Anthropic(api_key=Config.ANTHROPIC_API_KEY)\n",
        "\n",
        "                # Create directories\n",
        "                os.makedirs(Config.OUTPUT_PATH, exist_ok=True)\n",
        "                os.makedirs(Config.VERSION_PATH, exist_ok=True)\n",
        "\n",
        "                print(\"✅ Configuration applied successfully!\")\n",
        "                print(f\"📊 Max Codes: {Config.MAX_INITIAL_CODES}\")\n",
        "                print(f\"🔧 Chunk Size: {Config.CHUNK_SIZE} words\")\n",
        "                print(f\"🎯 Strategy: {Config.CODING_STRATEGY}\")\n",
        "                print(f\"🧠 Model: {Config.MODEL}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error applying configuration: {e}\")\n",
        "\n",
        "    def test_api_key(b):\n",
        "        with status_output:\n",
        "            status_output.clear_output()\n",
        "            try:\n",
        "                if not api_key_widget.value:\n",
        "                    print(\"❌ Please enter an API key first\")\n",
        "                    return\n",
        "\n",
        "                print(\"🔄 Testing API connection...\")\n",
        "                test_client = anthropic.Anthropic(api_key=api_key_widget.value)\n",
        "\n",
        "                response = test_client.messages.create(\n",
        "                    model=model_widget.value,\n",
        "                    max_tokens=10,\n",
        "                    messages=[{\"role\": \"user\", \"content\": \"Hello\"}]\n",
        "                )\n",
        "\n",
        "                print(\"✅ API key is valid and working!\")\n",
        "                print(f\"🤖 Model: {model_widget.value}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ API test failed: {e}\")\n",
        "\n",
        "    def reset_configuration(b):\n",
        "        with status_output:\n",
        "            status_output.clear_output()\n",
        "            # Reset all widgets to defaults\n",
        "            api_key_widget.value = \"\"\n",
        "            model_widget.value = \"claude-sonnet-4-20250514\"\n",
        "            max_codes_widget.value = 40\n",
        "            max_label_length_widget.value = 25\n",
        "            min_definition_length_widget.value = 20\n",
        "            min_examples_widget.value = 2\n",
        "            min_frequency_widget.value = 2\n",
        "            similarity_threshold_widget.value = 0.85\n",
        "            chunk_size_widget.value = 500\n",
        "            overlap_widget.value = 50\n",
        "            max_tokens_widget.value = 4000\n",
        "            temperature_widget.value = 0.3\n",
        "            purpose_widget.value = \"Extract theoretical and methodological codes from academic literature\"\n",
        "            epistemological_widget.value = \"pragmatic\"\n",
        "            coding_strategy_widget.value = \"hybrid\"\n",
        "            print(\"🔄 Configuration reset to defaults\")\n",
        "\n",
        "    # Bind events\n",
        "    apply_button.on_click(apply_configuration)\n",
        "    test_api_button.on_click(test_api_key)\n",
        "    reset_button.on_click(reset_configuration)\n",
        "\n",
        "    # Help text\n",
        "    help_html = \"\"\"\n",
        "    <div style='background-color: #f0f8ff; padding: 15px; border-radius: 5px; margin: 10px 0;'>\n",
        "    <h4>📖 Configuration Guide</h4>\n",
        "    <ul>\n",
        "        <li><strong>Max Initial Codes:</strong> Limits extracted codes to prevent cognitive overload</li>\n",
        "        <li><strong>Chunk Size:</strong> Number of words per text segment (larger = more context, slower processing)</li>\n",
        "        <li><strong>Similarity Threshold:</strong> How similar codes must be to trigger merge consideration (0.85 = 85% similar)</li>\n",
        "        <li><strong>Temperature:</strong> LLM creativity (0.0 = deterministic, 1.0 = creative)</li>\n",
        "        <li><strong>Coding Strategy:</strong>\n",
        "            <ul>\n",
        "                <li><em>Deductive:</em> Extract known theoretical frameworks</li>\n",
        "                <li><em>Inductive:</em> Discover emergent themes</li>\n",
        "                <li><em>Hybrid:</em> Combine both approaches (recommended)</li>\n",
        "            </ul>\n",
        "        </li>\n",
        "    </ul>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "    # Layout\n",
        "    api_section = widgets.VBox([api_header, api_key_widget, model_widget])\n",
        "    codebook_section = widgets.VBox([codebook_header, max_codes_widget, max_label_length_widget,\n",
        "                                   min_definition_length_widget, min_examples_widget])\n",
        "    quality_section = widgets.VBox([quality_header, min_frequency_widget, similarity_threshold_widget])\n",
        "    processing_section = widgets.VBox([processing_header, chunk_size_widget, overlap_widget])\n",
        "    llm_section = widgets.VBox([llm_header, max_tokens_widget, temperature_widget])\n",
        "    research_section = widgets.VBox([research_header, purpose_widget, epistemological_widget, coding_strategy_widget])\n",
        "\n",
        "    buttons_section = widgets.HBox([apply_button, test_api_button, reset_button])\n",
        "\n",
        "    # Display everything\n",
        "    display(HTML(help_html))\n",
        "    display(widgets.VBox([\n",
        "        api_section,\n",
        "        codebook_section,\n",
        "        quality_section,\n",
        "        processing_section,\n",
        "        llm_section,\n",
        "        research_section,\n",
        "        buttons_section,\n",
        "        status_output\n",
        "    ]))\n",
        "\n",
        "    return {\n",
        "        'api_key': api_key_widget,\n",
        "        'model': model_widget,\n",
        "        'max_codes': max_codes_widget,\n",
        "        'chunk_size': chunk_size_widget,\n",
        "        'temperature': temperature_widget,\n",
        "        'strategy': coding_strategy_widget,\n",
        "        'purpose': purpose_widget,\n",
        "        'apply_button': apply_button,\n",
        "        'test_button': test_api_button\n",
        "    }\n",
        "\n",
        "# CodeEntry class remains the same\n",
        "class CodeEntry:\n",
        "    \"\"\"Structure for each code following methodological guidelines\"\"\"\n",
        "    def __init__(self):\n",
        "        self.label = \"\"  # ≤25 chars, alphanumeric\n",
        "        self.definition = \"\"  # One litmus sentence\n",
        "        self.inclusion_criteria = []  # When to use\n",
        "        self.exclusion_criteria = []  # When NOT to use\n",
        "        self.examples = []  # 1-2 archetypal quotes\n",
        "        self.notes = []  # Analytic decisions, date-stamped\n",
        "        self.source_documents = []  # Where code was found\n",
        "        self.frequency = 0\n",
        "        self.created_date = datetime.now()\n",
        "        self.last_modified = datetime.now()\n",
        "        self.version = \"1.0.0\"\n",
        "\n",
        "# Create the interface\n",
        "print(\"🎛️ Loading Interactive Configuration...\")\n",
        "config_widgets = create_configuration_interface()"
      ],
      "metadata": {
        "id": "wtLfIRI4qzjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## File Upload and Processing\n",
        "\n"
      ],
      "metadata": {
        "id": "GCrS1VaClYHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This block handles file upload and text extraction from various file formats\n",
        "\n",
        "def upload_and_process_files():\n",
        "    \"\"\"Simple file upload and processing for Google Colab\"\"\"\n",
        "\n",
        "    print(\"=== File Upload Interface ===\")\n",
        "    print(\"Supported formats: PDF, DOCX, DOC, TXT, RTF, XLSX, CSV\")\n",
        "    print(\"\\nPlease select files to upload...\")\n",
        "\n",
        "    # Upload files\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"No files uploaded\")\n",
        "        return {}\n",
        "\n",
        "    print(f\"\\nUploaded {len(uploaded)} file(s)\")\n",
        "\n",
        "    documents = {}\n",
        "\n",
        "    for filename, content in uploaded.items():\n",
        "        try:\n",
        "            print(f\"\\nProcessing: {filename}\")\n",
        "            file_ext = filename.lower().split('.')[-1]\n",
        "\n",
        "            # Extract text based on file type\n",
        "            if file_ext == 'pdf':\n",
        "                text = extract_pdf_text(io.BytesIO(content))\n",
        "            elif file_ext in ['docx', 'doc']:\n",
        "                text = extract_docx_text(io.BytesIO(content))\n",
        "            elif file_ext == 'txt':\n",
        "                text = content.decode('utf-8', errors='ignore')\n",
        "            elif file_ext == 'rtf':\n",
        "                text = rtf_to_text(content.decode('utf-8', errors='ignore'))\n",
        "            elif file_ext == 'csv':\n",
        "                df = pd.read_csv(io.BytesIO(content))\n",
        "                text = extract_csv_text(df)\n",
        "            elif file_ext in ['xlsx', 'xls']:\n",
        "                df = pd.read_excel(io.BytesIO(content))\n",
        "                text = extract_excel_text(df)\n",
        "            else:\n",
        "                print(f\"  ⚠️  Unsupported file type: {file_ext}\")\n",
        "                continue\n",
        "\n",
        "            if text and len(text.strip()) > 0:\n",
        "                documents[filename] = text\n",
        "                print(f\"  ✓ Successfully loaded ({len(text)} characters)\")\n",
        "            else:\n",
        "                print(f\"  ✗ No text extracted from {filename}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ✗ Error loading {filename}: {str(e)}\")\n",
        "\n",
        "    print(f\"\\n✓ Successfully processed {len(documents)} documents\")\n",
        "    print(f\"Total characters: {sum(len(text) for text in documents.values()):,}\")\n",
        "\n",
        "    return documents\n",
        "\n",
        "def extract_pdf_text(file_content):\n",
        "    \"\"\"Extract text from PDF file\"\"\"\n",
        "    try:\n",
        "        pdf_reader = PyPDF2.PdfReader(file_content)\n",
        "        text = \"\"\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            page_text = pdf_reader.pages[page_num].extract_text()\n",
        "            if page_text:\n",
        "                text += page_text + \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"PDF extraction error: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def extract_docx_text(file_content):\n",
        "    \"\"\"Extract text from DOCX file\"\"\"\n",
        "    try:\n",
        "        doc = Document(file_content)\n",
        "        text = \"\"\n",
        "        # Extract from paragraphs\n",
        "        for paragraph in doc.paragraphs:\n",
        "            text += paragraph.text + \"\\n\"\n",
        "        # Extract from tables\n",
        "        for table in doc.tables:\n",
        "            for row in table.rows:\n",
        "                for cell in row.cells:\n",
        "                    text += cell.text + \" \"\n",
        "            text += \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"DOCX extraction error: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def extract_csv_text(df):\n",
        "    \"\"\"Extract text from CSV dataframe\"\"\"\n",
        "    text_columns = df.select_dtypes(include=['object']).columns\n",
        "    text = \"\"\n",
        "    for col in text_columns:\n",
        "        text += f\"Column: {col}\\n\"\n",
        "        text += \" \".join(df[col].dropna().astype(str).tolist()) + \"\\n\\n\"\n",
        "    return text\n",
        "\n",
        "def extract_excel_text(df):\n",
        "    \"\"\"Extract text from Excel dataframe\"\"\"\n",
        "    if isinstance(df, dict):  # Multiple sheets\n",
        "        text = \"\"\n",
        "        for sheet_name, sheet_df in df.items():\n",
        "            text += f\"Sheet: {sheet_name}\\n\"\n",
        "            text += extract_csv_text(sheet_df)\n",
        "    else:\n",
        "        text = extract_csv_text(df)\n",
        "    return text\n",
        "\n",
        "# Upload files now\n",
        "uploaded_documents = upload_and_process_files()"
      ],
      "metadata": {
        "id": "tdzviaKzla9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Chunking Utilities"
      ],
      "metadata": {
        "id": "TyyvKsbKlsw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This block provides utilities for splitting documents into manageable chunks\n",
        "\n",
        "def chunk_text(text: str, chunk_size: int = 500, overlap: int = 50) -> List[str]:\n",
        "    \"\"\"\n",
        "    Split text into overlapping chunks for processing.\n",
        "    Maintains context across chunk boundaries.\n",
        "    \"\"\"\n",
        "    sentences = sent_tokenize(text)\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_size = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentence_size = len(sentence.split())\n",
        "\n",
        "        if current_size + sentence_size > chunk_size and current_chunk:\n",
        "            chunks.append(\" \".join(current_chunk))\n",
        "            # Keep last few sentences for overlap\n",
        "            overlap_sentences = int(overlap * len(current_chunk) / current_size)\n",
        "            current_chunk = current_chunk[-overlap_sentences:] if overlap_sentences > 0 else []\n",
        "            current_size = sum(len(s.split()) for s in current_chunk)\n",
        "\n",
        "        current_chunk.append(sentence)\n",
        "        current_size += sentence_size\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(\" \".join(current_chunk))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "print(\"✓ Text chunking utilities loaded\")"
      ],
      "metadata": {
        "id": "4rGFF0q2lvlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Purpose and Scope Definition\n",
        "\n"
      ],
      "metadata": {
        "id": "crzlLWF6s9BR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This block defines the codebook's purpose and analyzes uploaded documents\n",
        "\n",
        "def define_codebook_purpose():\n",
        "    \"\"\"Step 1: Clarify purpose and scope following best practices\"\"\"\n",
        "\n",
        "    purpose_config = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"purpose\": Config.PURPOSE,\n",
        "        \"epistemological_stance\": Config.EPISTEMOLOGICAL_STANCE,\n",
        "        \"primary_use\": \"Extract theoretical constructs and methodological approaches from literature\",\n",
        "        \"intended_audience\": [\"Research team\", \"Peer reviewers\", \"Future researchers\"],\n",
        "        \"scope_limitations\": [\n",
        "            f\"Maximum {Config.MAX_INITIAL_CODES} initial codes to prevent overload\",\n",
        "            \"Focus on conceptual and methodological codes\",\n",
        "            \"Exclude purely descriptive or administrative codes\"\n",
        "        ],\n",
        "        \"research_questions\": [\n",
        "            \"What theoretical constructs are present in the literature?\",\n",
        "            \"What methodological approaches are discussed?\",\n",
        "            \"What key concepts require operational definitions?\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Save purpose statement\n",
        "    with open(f\"{Config.OUTPUT_PATH}codebook_purpose.json\", 'w') as f:\n",
        "        json.dump(purpose_config, f, indent=2)\n",
        "\n",
        "    return purpose_config\n",
        "\n",
        "def analyze_document_types(documents: Dict[str, str]) -> Dict:\n",
        "    \"\"\"Analyze uploaded documents to understand their nature - FULL DOCUMENT ANALYSIS\"\"\"\n",
        "\n",
        "    print(\"\\nAnalyzing document types and content...\")\n",
        "    document_analysis = {}\n",
        "\n",
        "    for doc_name, content in documents.items():\n",
        "        print(f\"  Analyzing: {doc_name}\")\n",
        "\n",
        "        # For very long documents, analyze in segments\n",
        "        segments = []\n",
        "        if len(content) > 10000:  # If document is very long\n",
        "            # Analyze beginning, middle, and end\n",
        "            segments = [\n",
        "                content[:3000],  # Beginning\n",
        "                content[len(content)//2 - 1500:len(content)//2 + 1500],  # Middle\n",
        "                content[-3000:]  # End\n",
        "            ]\n",
        "        else:\n",
        "            # Analyze the whole document if it's shorter\n",
        "            segments = [content]\n",
        "\n",
        "        combined_analysis = {\n",
        "            'document_type': [],\n",
        "            'domain': [],\n",
        "            'frameworks': [],\n",
        "            'methods': [],\n",
        "            'code_categories': []\n",
        "        }\n",
        "\n",
        "        # Analyze each segment\n",
        "        for i, segment in enumerate(segments):\n",
        "            analysis_prompt = f\"\"\"\n",
        "            Analyze this {'full document' if len(segments) == 1 else f'segment {i+1} of document'} to determine:\n",
        "            1. Document type (e.g., empirical article, theoretical paper, methodology guide, report)\n",
        "            2. Primary domain/field\n",
        "            3. Key theoretical frameworks mentioned\n",
        "            4. Methodological approaches discussed\n",
        "            5. Potential code categories to extract\n",
        "\n",
        "            Be comprehensive - identify ALL frameworks, methods, and concepts present.\n",
        "\n",
        "            Text:\n",
        "            {segment}\n",
        "\n",
        "            Return ONLY valid JSON without markdown formatting. Use this exact structure:\n",
        "            {{\n",
        "                \"document_type\": \"string\",\n",
        "                \"domain\": \"string\",\n",
        "                \"frameworks\": [\"list\", \"of\", \"frameworks\"],\n",
        "                \"methods\": [\"list\", \"of\", \"methods\"],\n",
        "                \"code_categories\": [\"list\", \"of\", \"categories\"]\n",
        "            }}\n",
        "            \"\"\"\n",
        "\n",
        "            try:\n",
        "                response = client.messages.create(\n",
        "                    model=Config.MODEL,\n",
        "                    max_tokens=1500,\n",
        "                    temperature=0.2,  # Lower temperature for consistent formatting\n",
        "                    messages=[{\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": analysis_prompt\n",
        "                    }],\n",
        "                    timeout=120.0\n",
        "                )\n",
        "\n",
        "                # Clean and parse the response\n",
        "                raw_response_text = response.content[0].text\n",
        "                print(f\"  Raw API response for segment {i+1}: {raw_response_text[:200]}...\")\n",
        "\n",
        "                try:\n",
        "                    cleaned_response = raw_response_text.strip()\n",
        "\n",
        "                    # Remove markdown code blocks\n",
        "                    if cleaned_response.startswith(\"```json\"):\n",
        "                        cleaned_response = cleaned_response[7:]\n",
        "                    if cleaned_response.startswith(\"```\"):\n",
        "                        cleaned_response = cleaned_response[3:]\n",
        "                    if cleaned_response.endswith(\"```\"):\n",
        "                        cleaned_response = cleaned_response[:-3]\n",
        "\n",
        "                    cleaned_response = cleaned_response.strip()\n",
        "\n",
        "                    # Parse JSON\n",
        "                    segment_analysis = json.loads(cleaned_response)\n",
        "\n",
        "                    # Aggregate results\n",
        "                    if isinstance(segment_analysis.get('document_type'), str):\n",
        "                        combined_analysis['document_type'].append(segment_analysis['document_type'])\n",
        "                    if isinstance(segment_analysis.get('domain'), str):\n",
        "                        combined_analysis['domain'].append(segment_analysis['domain'])\n",
        "\n",
        "                    for key in ['frameworks', 'methods', 'code_categories']:\n",
        "                        if isinstance(segment_analysis.get(key), list):\n",
        "                            combined_analysis[key].extend(segment_analysis[key])\n",
        "\n",
        "                except json.JSONDecodeError as e:\n",
        "                    print(f\"    JSON parsing error for segment {i+1}: {e}\")\n",
        "                    print(f\"    Raw response (first 200 chars): {raw_response_text[:200]}...\")\n",
        "                    continue\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"    Error analyzing segment {i+1}: {str(e)}\")\n",
        "\n",
        "        # Consolidate analysis\n",
        "        document_analysis[doc_name] = {\n",
        "            'document_type': Counter(combined_analysis['document_type']).most_common(1)[0][0] if combined_analysis['document_type'] else 'Unknown',\n",
        "            'domain': Counter(combined_analysis['domain']).most_common(1)[0][0] if combined_analysis['domain'] else 'Unknown',\n",
        "            'frameworks': list(set(combined_analysis['frameworks'])),  # Unique frameworks\n",
        "            'methods': list(set(combined_analysis['methods'])),  # Unique methods\n",
        "            'code_categories': list(set(combined_analysis['code_categories'])),  # Unique categories\n",
        "            'document_length': len(content),\n",
        "            'segments_analyzed': len(segments)\n",
        "        }\n",
        "\n",
        "        print(f\"    Found {len(document_analysis[doc_name]['frameworks'])} frameworks, \"\n",
        "              f\"{len(document_analysis[doc_name]['methods'])} methods\")\n",
        "\n",
        "    # Save analysis\n",
        "    with open(f\"{Config.OUTPUT_PATH}document_analysis.json\", 'w') as f:\n",
        "        json.dump(document_analysis, f, indent=2)\n",
        "\n",
        "    return document_analysis"
      ],
      "metadata": {
        "id": "bYaD3Stvl4-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial Code Extraction\n",
        "\n"
      ],
      "metadata": {
        "id": "frX-Fp0ftAmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This block extracts initial codes from documents using the specified coding strategy\n",
        "\n",
        "def extract_initial_codes(documents: Dict[str, str],\n",
        "                         coding_strategy: str = \"hybrid\") -> Tuple[Dict[str, CodeEntry], List]:\n",
        "    \"\"\"\n",
        "    Step 3: Build initial code set using parallel deductive + inductive generation\n",
        "    \"\"\"\n",
        "\n",
        "    codebook = {}\n",
        "    extraction_log = []\n",
        "\n",
        "    # Define extraction prompt based on strategy\n",
        "    if coding_strategy == \"inductive\":\n",
        "        prompt_template = \"\"\"\n",
        "        Using inductive coding, extract potential codes from the provided text.\n",
        "        Focus on:\n",
        "        - Theoretical concepts and constructs\n",
        "        - Methodological approaches\n",
        "        - Key terms that appear multiple times\n",
        "        - Conceptual frameworks\n",
        "\n",
        "        For each code provide:\n",
        "        - label: ≤25 characters, alphanumeric only, no spaces (use_underscores)\n",
        "        - definition: One clear sentence defining the concept\n",
        "        - example: Direct quote showing the concept\n",
        "        - context: Why this is a meaningful code\n",
        "\n",
        "        Text:\n",
        "        {text}\n",
        "\n",
        "        Return ONLY valid JSON without markdown formatting. Structure as array:\n",
        "        [\n",
        "          {{\n",
        "            \"label\": \"code_name\",\n",
        "            \"definition\": \"definition text\",\n",
        "            \"example\": \"quote example\",\n",
        "            \"context\": \"context explanation\"\n",
        "          }}\n",
        "        ]\n",
        "        \"\"\"\n",
        "\n",
        "    elif coding_strategy == \"deductive\":\n",
        "        prompt_template = \"\"\"\n",
        "        Extract codes from the provided text based on established theoretical frameworks.\n",
        "        Look specifically for:\n",
        "        - Established theories (e.g., grounded theory, phenomenology)\n",
        "        - Standard methodological approaches\n",
        "        - Common analytical frameworks\n",
        "        - Disciplinary conventions\n",
        "\n",
        "        Format requirements:\n",
        "        - label: ≤25 characters, alphanumeric only\n",
        "        - definition: One litmus sentence\n",
        "        - example: Supporting quote\n",
        "\n",
        "        Text:\n",
        "        {text}\n",
        "\n",
        "        Return ONLY valid JSON without markdown formatting. Structure as array:\n",
        "        [\n",
        "          {{\n",
        "            \"label\": \"code_name\",\n",
        "            \"definition\": \"definition text\",\n",
        "            \"example\": \"quote example\"\n",
        "          }}\n",
        "        ]\n",
        "        \"\"\"\n",
        "\n",
        "    else:  # hybrid - most common\n",
        "        prompt_template = \"\"\"\n",
        "        Extract codes from the provided text using a hybrid approach.\n",
        "\n",
        "        First, identify standard theoretical/methodological codes:\n",
        "        - Established frameworks and theories\n",
        "        - Research design elements\n",
        "        - Analytical approaches\n",
        "\n",
        "        Then, identify emergent codes unique to this text:\n",
        "        - Novel concepts introduced\n",
        "        - Specific constructs defined\n",
        "        - Unique methodological innovations\n",
        "\n",
        "        For each code:\n",
        "        - label: ≤25 characters, alphanumeric, no spaces\n",
        "        - definition: One sentence \"litmus test\" definition\n",
        "        - code_type: \"deductive\" or \"inductive\"\n",
        "        - example: Direct quote (50-150 words)\n",
        "        - inclusion: When to use this code\n",
        "        - exclusion: When NOT to use this code\n",
        "\n",
        "        Text:\n",
        "        {text}\n",
        "\n",
        "        Return ONLY valid JSON without markdown formatting. Structure as array:\n",
        "        [\n",
        "          {{\n",
        "            \"label\": \"code_name\",\n",
        "            \"definition\": \"definition text\",\n",
        "            \"code_type\": \"deductive\",\n",
        "            \"example\": \"quote example\",\n",
        "            \"inclusion\": \"when to use\",\n",
        "            \"exclusion\": \"when not to use\"\n",
        "          }}\n",
        "        ]\n",
        "        \"\"\"\n",
        "\n",
        "    # Process each document\n",
        "    successful_extractions = 0\n",
        "    failed_extractions = 0\n",
        "\n",
        "    for doc_name, content in documents.items():\n",
        "        print(f\"\\nExtracting codes from: {doc_name}\")\n",
        "\n",
        "        # Chunk the document\n",
        "        chunks = chunk_text(content, Config.CHUNK_SIZE, Config.OVERLAP)\n",
        "\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            if i % 3 == 0:\n",
        "                print(f\"  Processing chunk {i+1}/{len(chunks)} (Success: {successful_extractions}, Failed: {failed_extractions})\")\n",
        "\n",
        "            try:\n",
        "                response = client.messages.create(\n",
        "                    model=Config.MODEL,\n",
        "                    max_tokens=2000,\n",
        "                    temperature=0.2,  # Lower temperature for consistent formatting\n",
        "                    messages=[{\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": prompt_template.format(text=chunk)\n",
        "                    }],\n",
        "                    timeout=120.0\n",
        "                )\n",
        "\n",
        "                # Clean and parse the response\n",
        "                raw_response_text = response.content[0].text\n",
        "\n",
        "                try:\n",
        "                    cleaned_response = raw_response_text.strip()\n",
        "\n",
        "                    # Remove markdown code blocks\n",
        "                    if cleaned_response.startswith(\"```json\"):\n",
        "                        cleaned_response = cleaned_response[7:]\n",
        "                    if cleaned_response.startswith(\"```\"):\n",
        "                        cleaned_response = cleaned_response[3:]\n",
        "                    if cleaned_response.endswith(\"```\"):\n",
        "                        cleaned_response = cleaned_response[:-3]\n",
        "\n",
        "                    cleaned_response = cleaned_response.strip()\n",
        "\n",
        "                    # Parse JSON\n",
        "                    extracted_codes = json.loads(cleaned_response)\n",
        "\n",
        "                    # Ensure it's a list\n",
        "                    if not isinstance(extracted_codes, list):\n",
        "                        print(f\"  Warning: Expected list but got {type(extracted_codes)} for chunk {i}\")\n",
        "                        continue\n",
        "\n",
        "                    # Process each extracted code\n",
        "                    codes_added_this_chunk = 0\n",
        "                    for code_data in extracted_codes:\n",
        "                        if not isinstance(code_data, dict):\n",
        "                            continue\n",
        "\n",
        "                        label = sanitize_code_label(code_data.get('label', f'UNKNOWN_CODE_{i}'))\n",
        "\n",
        "                        if not label or label == 'UNKNOWN_CODE':\n",
        "                            continue\n",
        "\n",
        "                        if label not in codebook:\n",
        "                            # Create new code entry\n",
        "                            code = CodeEntry()\n",
        "                            code.label = label\n",
        "                            code.definition = code_data.get('definition', 'No definition provided')\n",
        "                            code.source_documents.append(doc_name)\n",
        "                            code.frequency = 1\n",
        "\n",
        "                            # Add example\n",
        "                            example_text = code_data.get('example', 'No example provided')\n",
        "                            code.examples.append({\n",
        "                                'text': example_text[:500],  # Limit example length\n",
        "                                'source': doc_name,\n",
        "                                'chunk': i\n",
        "                            })\n",
        "\n",
        "                            # Add criteria if provided\n",
        "                            if 'inclusion' in code_data:\n",
        "                                code.inclusion_criteria.append(code_data['inclusion'])\n",
        "                            if 'exclusion' in code_data:\n",
        "                                code.exclusion_criteria.append(code_data['exclusion'])\n",
        "\n",
        "                            # Add note about extraction\n",
        "                            code.notes.append({\n",
        "                                'date': datetime.now().isoformat(),\n",
        "                                'note': f\"Extracted via {coding_strategy} coding from {doc_name}\",\n",
        "                                'context': code_data.get('context', '')\n",
        "                            })\n",
        "\n",
        "                            codebook[label] = code\n",
        "                            codes_added_this_chunk += 1\n",
        "\n",
        "                        else:\n",
        "                            # Update existing code\n",
        "                            codebook[label].frequency += 1\n",
        "                            if doc_name not in codebook[label].source_documents:\n",
        "                                codebook[label].source_documents.append(doc_name)\n",
        "\n",
        "                            # Add additional example if different enough\n",
        "                            if len(codebook[label].examples) < Config.MIN_EXAMPLES_PER_CODE:\n",
        "                                codebook[label].examples.append({\n",
        "                                    'text': code_data.get('example', 'No example provided')[:500],\n",
        "                                    'source': doc_name,\n",
        "                                    'chunk': i\n",
        "                                })\n",
        "\n",
        "                        # Log extraction\n",
        "                        extraction_log.append({\n",
        "                            'timestamp': datetime.now().isoformat(),\n",
        "                            'document': doc_name,\n",
        "                            'chunk': i,\n",
        "                            'code': label,\n",
        "                            'action': 'created' if codebook[label].frequency == 1 else 'updated'\n",
        "                        })\n",
        "\n",
        "                    successful_extractions += 1\n",
        "                    if codes_added_this_chunk > 0:\n",
        "                        print(f\"    Added {codes_added_this_chunk} new codes from chunk {i}\")\n",
        "\n",
        "                except json.JSONDecodeError as e:\n",
        "                    failed_extractions += 1\n",
        "                    print(f\"  JSON parsing failed for chunk {i}: {e}\")\n",
        "                    print(f\"  Raw response (first 300 chars): {raw_response_text[:300]}...\")\n",
        "\n",
        "                    # Save problematic response for debugging\n",
        "                    with open(f\"{Config.OUTPUT_PATH}debug_chunk_{doc_name}_{i}.txt\", 'w') as f:\n",
        "                        f.write(f\"Original:\\n{raw_response_text}\\n\\nCleaned:\\n{cleaned_response}\")\n",
        "\n",
        "                time.sleep(0.5)  # Rate limiting\n",
        "\n",
        "            except Exception as e:\n",
        "                failed_extractions += 1\n",
        "                print(f\"Error processing chunk {i}: {str(e)}\")\n",
        "\n",
        "    print(f\"\\nExtraction Summary:\")\n",
        "    print(f\"  Successful chunks: {successful_extractions}\")\n",
        "    print(f\"  Failed chunks: {failed_extractions}\")\n",
        "    print(f\"  Total codes extracted: {len(codebook)}\")\n",
        "\n",
        "    return codebook, extraction_log\n",
        "\n",
        "def sanitize_code_label(label: str) -> str:\n",
        "    \"\"\"Ensure code label meets requirements: ≤25 chars, alphanumeric only\"\"\"\n",
        "    # Remove non-alphanumeric characters\n",
        "    label = re.sub(r'[^a-zA-Z0-9_]', '_', label)\n",
        "    # Remove multiple underscores\n",
        "    label = re.sub(r'_+', '_', label)\n",
        "    # Trim to length\n",
        "    label = label[:Config.MAX_CODE_LABEL_LENGTH]\n",
        "    # Remove trailing underscores\n",
        "    label = label.strip('_')\n",
        "    return label.upper()  # Uppercase for consistency"
      ],
      "metadata": {
        "id": "kcZZybC6tFp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code Refinement and Merging\n"
      ],
      "metadata": {
        "id": "qjPj5DMItHd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This block handles the refinement of codes including merging similar codes\n",
        "\n",
        "def refine_and_assess_reliability(codebook: Dict[str, CodeEntry]) -> Tuple[Dict, Dict]:\n",
        "    \"\"\"\n",
        "    Step 4: Refine codes and assess conceptual reliability\n",
        "    Following guidelines for intercoder reliability in manual coding\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n=== Codebook Refinement Process ===\")\n",
        "\n",
        "    # 1. Prune rare codes\n",
        "    print(\"\\n1. Pruning rare codes...\")\n",
        "    refined_codebook = {}\n",
        "    for label, code in codebook.items():\n",
        "        if code.frequency >= Config.MIN_CODE_FREQUENCY:\n",
        "            refined_codebook[label] = code\n",
        "        else:\n",
        "            print(f\"  Removed: {label} (frequency: {code.frequency})\")\n",
        "\n",
        "    print(f\"  Retained {len(refined_codebook)} codes\")\n",
        "\n",
        "    # 2. Check for conceptual overlap and merge similar codes\n",
        "    print(\"\\n2. Checking for conceptual overlap...\")\n",
        "    merge_decisions = identify_similar_codes(refined_codebook)\n",
        "\n",
        "    # 3. Apply merges\n",
        "    for decision in merge_decisions:\n",
        "        if decision['should_merge']:\n",
        "            refined_codebook = merge_codes(\n",
        "                refined_codebook,\n",
        "                decision['code1'],\n",
        "                decision['code2'],\n",
        "                decision['merged_label'],\n",
        "                decision['merged_definition']\n",
        "            )\n",
        "\n",
        "    # 4. Ensure all codes have complete definitions\n",
        "    print(\"\\n3. Validating code completeness...\")\n",
        "    validation_report = validate_codes(refined_codebook)\n",
        "\n",
        "    # 5. Generate reliability metrics (conceptual distinctness)\n",
        "    print(\"\\n4. Assessing conceptual distinctness...\")\n",
        "    reliability_metrics = assess_conceptual_distinctness(refined_codebook)\n",
        "\n",
        "    return refined_codebook, {\n",
        "        'validation': validation_report,\n",
        "        'reliability': reliability_metrics,\n",
        "        'merge_decisions': merge_decisions\n",
        "    }\n",
        "\n",
        "def identify_similar_codes(codebook: Dict[str, CodeEntry]) -> List[Dict]:\n",
        "    \"\"\"Identify codes that may need merging\"\"\"\n",
        "\n",
        "    if len(codebook) < 2:\n",
        "        return []\n",
        "\n",
        "    # Create embeddings\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    code_labels = list(codebook.keys())\n",
        "\n",
        "    # Combine label, definition, and examples for embedding\n",
        "    code_texts = []\n",
        "    for label in code_labels:\n",
        "        code = codebook[label]\n",
        "        examples_text = \" \".join([ex['text'][:100] for ex in code.examples[:2]])\n",
        "        code_text = f\"{label}: {code.definition}. Examples: {examples_text}\"\n",
        "        code_texts.append(code_text)\n",
        "\n",
        "    embeddings = model.encode(code_texts)\n",
        "    similarity_matrix = cosine_similarity(embeddings)\n",
        "\n",
        "    # Find similar pairs\n",
        "    merge_candidates = []\n",
        "\n",
        "    for i in range(len(code_labels)):\n",
        "        for j in range(i + 1, len(code_labels)):\n",
        "            if similarity_matrix[i][j] > Config.SIMILARITY_THRESHOLD:\n",
        "                # Use LLM to make merge decision\n",
        "                decision = evaluate_merge_decision(\n",
        "                    codebook[code_labels[i]],\n",
        "                    codebook[code_labels[j]],\n",
        "                    similarity_matrix[i][j]\n",
        "                )\n",
        "                merge_candidates.append(decision)\n",
        "\n",
        "    return merge_candidates\n",
        "\n",
        "def evaluate_merge_decision(code1: CodeEntry, code2: CodeEntry, similarity: float) -> Dict:\n",
        "    \"\"\"Use LLM to evaluate whether codes should be merged\"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Evaluate whether these two codes should be merged based on conceptual overlap.\n",
        "\n",
        "    Similarity score: {similarity:.2f}\n",
        "\n",
        "    Code 1: {code1.label}\n",
        "    Definition: {code1.definition}\n",
        "    Example: {code1.examples[0]['text'] if code1.examples else 'No example'}\n",
        "\n",
        "    Code 2: {code2.label}\n",
        "    Definition: {code2.definition}\n",
        "    Example: {code2.examples[0]['text'] if code2.examples else 'No example'}\n",
        "\n",
        "    Consider:\n",
        "    - Are these conceptually distinct despite similar language?\n",
        "    - Would merging lose important nuance?\n",
        "    - Is one a subset of the other?\n",
        "\n",
        "    Return ONLY valid JSON without markdown formatting:\n",
        "    {{\n",
        "        \"should_merge\": true,\n",
        "        \"rationale\": \"explanation of decision\",\n",
        "        \"merged_label\": \"suggested_label_if_merging\",\n",
        "        \"merged_definition\": \"comprehensive definition if merging\"\n",
        "    }}\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.messages.create(\n",
        "            model=Config.MODEL,\n",
        "            max_tokens=500,\n",
        "            temperature=0.2,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "\n",
        "        # Clean and parse response\n",
        "        raw_text = response.content[0].text\n",
        "\n",
        "        try:\n",
        "            cleaned_response = raw_text.strip()\n",
        "\n",
        "            # Remove markdown code blocks\n",
        "            if cleaned_response.startswith(\"```json\"):\n",
        "                cleaned_response = cleaned_response[7:]\n",
        "            if cleaned_response.startswith(\"```\"):\n",
        "                cleaned_response = cleaned_response[3:]\n",
        "            if cleaned_response.endswith(\"```\"):\n",
        "                cleaned_response = cleaned_response[:-3]\n",
        "\n",
        "            cleaned_response = cleaned_response.strip()\n",
        "\n",
        "            decision = json.loads(cleaned_response)\n",
        "\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"JSON parsing error in merge evaluation: {e}\")\n",
        "            decision = {\n",
        "                'should_merge': False,\n",
        "                'rationale': 'Error parsing response'\n",
        "            }\n",
        "\n",
        "        decision['code1'] = code1.label\n",
        "        decision['code2'] = code2.label\n",
        "        decision['similarity'] = similarity\n",
        "\n",
        "        return decision\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error evaluating merge: {str(e)}\")\n",
        "        return {\n",
        "            'code1': code1.label,\n",
        "            'code2': code2.label,\n",
        "            'should_merge': False,\n",
        "            'rationale': 'Error in evaluation'\n",
        "        }\n",
        "\n",
        "def merge_codes(codebook: Dict, code1: str, code2: str,\n",
        "                merged_label: str, merged_definition: str) -> Dict:\n",
        "    \"\"\"Merge two codes into one\"\"\"\n",
        "    if code1 in codebook and code2 in codebook:\n",
        "        # Create merged code\n",
        "        merged_code = codebook[code1]\n",
        "        merged_code.label = sanitize_code_label(merged_label)\n",
        "        merged_code.definition = merged_definition\n",
        "\n",
        "        # Combine examples\n",
        "        merged_code.examples.extend(codebook[code2].examples)\n",
        "        merged_code.frequency += codebook[code2].frequency\n",
        "\n",
        "        # Combine source documents\n",
        "        merged_code.source_documents = list(set(\n",
        "            merged_code.source_documents + codebook[code2].source_documents\n",
        "        ))\n",
        "\n",
        "        # Add merge note\n",
        "        merged_code.notes.append({\n",
        "            'date': datetime.now().isoformat(),\n",
        "            'note': f\"Merged with {code2}\",\n",
        "            'context': 'Conceptual similarity detected'\n",
        "        })\n",
        "\n",
        "        # Remove old codes and add merged\n",
        "        del codebook[code1]\n",
        "        del codebook[code2]\n",
        "        codebook[merged_code.label] = merged_code\n",
        "\n",
        "    return codebook"
      ],
      "metadata": {
        "id": "P6rxPKiKtKxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quality Validation\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "c4Ga7ehetOwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This block validates the quality of extracted codes\n",
        "\n",
        "def validate_codes(codebook: Dict[str, CodeEntry]) -> Dict:\n",
        "    \"\"\"Validate each code meets quality criteria\"\"\"\n",
        "\n",
        "    validation_results = {\n",
        "        'total_codes': len(codebook),\n",
        "        'issues_by_code': {},\n",
        "        'summary': {\n",
        "            'missing_definitions': 0,\n",
        "            'short_definitions': 0,\n",
        "            'missing_inclusion': 0,\n",
        "            'missing_exclusion': 0,\n",
        "            'insufficient_examples': 0\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if len(codebook) == 0:\n",
        "        validation_results['quality_score'] = 0.0\n",
        "        return validation_results\n",
        "\n",
        "    for label, code in codebook.items():\n",
        "        issues = []\n",
        "\n",
        "        # Check definition\n",
        "        if not code.definition:\n",
        "            issues.append(\"Missing definition\")\n",
        "            validation_results['summary']['missing_definitions'] += 1\n",
        "        elif len(code.definition) < Config.MIN_DEFINITION_LENGTH:\n",
        "            issues.append(f\"Definition too short ({len(code.definition)} chars)\")\n",
        "            validation_results['summary']['short_definitions'] += 1\n",
        "\n",
        "        # Check criteria\n",
        "        if not code.inclusion_criteria:\n",
        "            issues.append(\"Missing inclusion criteria\")\n",
        "            validation_results['summary']['missing_inclusion'] += 1\n",
        "\n",
        "        if not code.exclusion_criteria:\n",
        "            issues.append(\"Missing exclusion criteria\")\n",
        "            validation_results['summary']['missing_exclusion'] += 1\n",
        "\n",
        "        # Check examples\n",
        "        if len(code.examples) < Config.MIN_EXAMPLES_PER_CODE:\n",
        "            issues.append(f\"Insufficient examples ({len(code.examples)})\")\n",
        "            validation_results['summary']['insufficient_examples'] += 1\n",
        "\n",
        "        if issues:\n",
        "            validation_results['issues_by_code'][label] = issues\n",
        "\n",
        "    validation_results['quality_score'] = 1 - (\n",
        "        len(validation_results['issues_by_code']) / len(codebook)\n",
        "    )\n",
        "\n",
        "    return validation_results\n",
        "\n",
        "def assess_conceptual_distinctness(codebook: Dict[str, CodeEntry]) -> Dict:\n",
        "    \"\"\"Assess how conceptually distinct codes are from each other\"\"\"\n",
        "\n",
        "    if len(codebook) < 2:\n",
        "        return {'average_distinctness': 1.0, 'min_distinctness': 1.0, 'overlap_pairs': []}\n",
        "\n",
        "    # Create embeddings for all codes\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    code_labels = list(codebook.keys())\n",
        "\n",
        "    code_representations = []\n",
        "    for label in code_labels:\n",
        "        code = codebook[label]\n",
        "        # Combine all information about the code\n",
        "        representation = f\"{label} {code.definition} \"\n",
        "        representation += \" \".join(code.inclusion_criteria)\n",
        "        representation += \" \".join(code.exclusion_criteria)\n",
        "        code_representations.append(representation)\n",
        "\n",
        "    embeddings = model.encode(code_representations)\n",
        "    similarity_matrix = cosine_similarity(embeddings)\n",
        "\n",
        "    # Calculate distinctness metrics\n",
        "    overlap_pairs = []\n",
        "    distinctness_scores = []\n",
        "\n",
        "    for i in range(len(code_labels)):\n",
        "        max_similarity = 0\n",
        "        for j in range(len(code_labels)):\n",
        "            if i != j:\n",
        "                max_similarity = max(max_similarity, similarity_matrix[i][j])\n",
        "                if similarity_matrix[i][j] > 0.7:  # Concerning overlap\n",
        "                    overlap_pairs.append({\n",
        "                        'code1': code_labels[i],\n",
        "                        'code2': code_labels[j],\n",
        "                        'similarity': float(similarity_matrix[i][j])\n",
        "                    })\n",
        "\n",
        "        distinctness_scores.append(1 - max_similarity)\n",
        "\n",
        "    return {\n",
        "        'average_distinctness': float(np.mean(distinctness_scores)),\n",
        "        'min_distinctness': float(np.min(distinctness_scores)),\n",
        "        'overlap_pairs': overlap_pairs[:10]  # Top 10 overlapping pairs\n",
        "    }"
      ],
      "metadata": {
        "id": "TT9KkjoDtQDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Version Control System\n"
      ],
      "metadata": {
        "id": "F382wNxltVRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This block implements semantic versioning for the codebook\n",
        "\n",
        "class CodebookVersionControl:\n",
        "    \"\"\"Implement semantic versioning and change tracking\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.current_version = \"1.0.0\"\n",
        "        self.changelog = []\n",
        "        self.version_history = {}\n",
        "\n",
        "    def save_version(self, codebook: Dict[str, CodeEntry], change_description: str):\n",
        "        \"\"\"Save a version with changelog entry\"\"\"\n",
        "\n",
        "        # Create version snapshot\n",
        "        snapshot = {\n",
        "            'version': self.current_version,\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'num_codes': len(codebook),\n",
        "            'change_description': change_description,\n",
        "            'codebook_snapshot': self._serialize_codebook(codebook)\n",
        "        }\n",
        "\n",
        "        # Calculate checksum\n",
        "        checksum = hashlib.md5(\n",
        "            json.dumps(snapshot['codebook_snapshot'], sort_keys=True).encode()\n",
        "        ).hexdigest()\n",
        "        snapshot['checksum'] = checksum\n",
        "\n",
        "        # Save to version history\n",
        "        filename = f\"{Config.VERSION_PATH}codebook_v{self.current_version}.json\"\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(snapshot, f, indent=2)\n",
        "\n",
        "        # Update changelog\n",
        "        self.changelog.append({\n",
        "            'version': self.current_version,\n",
        "            'date': datetime.now().isoformat(),\n",
        "            'changes': change_description,\n",
        "            'checksum': checksum\n",
        "        })\n",
        "\n",
        "        # Save changelog\n",
        "        with open(f\"{Config.VERSION_PATH}CHANGELOG.json\", 'w') as f:\n",
        "            json.dump(self.changelog, f, indent=2)\n",
        "\n",
        "        print(f\"Saved version {self.current_version}: {change_description}\")\n",
        "\n",
        "    def increment_version(self, change_type: str = \"patch\"):\n",
        "        \"\"\"Increment version number (major.minor.patch)\"\"\"\n",
        "        major, minor, patch = map(int, self.current_version.split('.'))\n",
        "\n",
        "        if change_type == \"major\":\n",
        "            major += 1\n",
        "            minor = 0\n",
        "            patch = 0\n",
        "        elif change_type == \"minor\":\n",
        "            minor += 1\n",
        "            patch = 0\n",
        "        else:  # patch\n",
        "            patch += 1\n",
        "\n",
        "        self.current_version = f\"{major}.{minor}.{patch}\"\n",
        "        return self.current_version\n",
        "\n",
        "    def _serialize_codebook(self, codebook: Dict[str, CodeEntry]) -> Dict:\n",
        "        \"\"\"Convert CodeEntry objects to JSON-serializable format\"\"\"\n",
        "        serialized = {}\n",
        "        for label, code in codebook.items():\n",
        "            serialized[label] = {\n",
        "                'label': code.label,\n",
        "                'definition': code.definition,\n",
        "                'inclusion_criteria': code.inclusion_criteria,\n",
        "                'exclusion_criteria': code.exclusion_criteria,\n",
        "                'examples': code.examples,\n",
        "                'notes': code.notes,\n",
        "                'source_documents': code.source_documents,\n",
        "                'frequency': code.frequency,\n",
        "                'created_date': code.created_date.isoformat(),\n",
        "                'last_modified': code.last_modified.isoformat(),\n",
        "                'version': code.version\n",
        "            }\n",
        "        return serialized\n",
        "\n",
        "# Initialize version control\n",
        "version_control = CodebookVersionControl()\n",
        "print(\"✓ Version control initialized\")"
      ],
      "metadata": {
        "id": "EqwDz25RtYm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export Functions\n",
        "\n"
      ],
      "metadata": {
        "id": "i23lydrTtbjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This block handles exporting the codebook in various formats\n",
        "\n",
        "def export_codebook_formats(codebook: Dict[str, CodeEntry],\n",
        "                          assessment_report: Dict,\n",
        "                          purpose_config: Dict):\n",
        "    \"\"\"\n",
        "    Step 6: Format for human and machine readability\n",
        "    Export in multiple formats as recommended\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. CSV format (for quantitative linkage)\n",
        "    export_to_csv(codebook)\n",
        "\n",
        "    # 2. JSON format (for software integration)\n",
        "    export_to_json(codebook, assessment_report)\n",
        "\n",
        "    # 3. Human-readable markdown\n",
        "    export_to_markdown(codebook, assessment_report, purpose_config)\n",
        "\n",
        "    # 4. ATLAS.ti compatible format\n",
        "    export_to_atlas_format(codebook)\n",
        "\n",
        "    # 5. NVivo compatible format\n",
        "    export_to_nvivo_format(codebook)\n",
        "\n",
        "    print(f\"\\nExported codebook in 5 formats to {Config.OUTPUT_PATH}\")\n",
        "\n",
        "def export_to_csv(codebook: Dict[str, CodeEntry]):\n",
        "    \"\"\"Export as CSV with proper formatting\"\"\"\n",
        "\n",
        "    rows = []\n",
        "    for label, code in codebook.items():\n",
        "        row = {\n",
        "            'code_label': label,\n",
        "            'definition': code.definition,\n",
        "            'inclusion_criteria': '; '.join(code.inclusion_criteria),\n",
        "            'exclusion_criteria': '; '.join(code.exclusion_criteria),\n",
        "            'example_1': code.examples[0]['text'] if code.examples else '',\n",
        "            'example_2': code.examples[1]['text'] if len(code.examples) > 1 else '',\n",
        "            'frequency': code.frequency,\n",
        "            'source_documents': '; '.join(code.source_documents),\n",
        "            'created_date': code.created_date.strftime('%Y-%m-%d'),\n",
        "            'version': code.version\n",
        "        }\n",
        "        rows.append(row)\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    df.to_csv(f\"{Config.OUTPUT_PATH}codebook.csv\", index=False)\n",
        "\n",
        "def export_to_json(codebook: Dict[str, CodeEntry], assessment_report: Dict):\n",
        "    \"\"\"Export as JSON for software integration\"\"\"\n",
        "\n",
        "    json_export = {\n",
        "        'metadata': {\n",
        "            'version': version_control.current_version,\n",
        "            'created': datetime.now().isoformat(),\n",
        "            'total_codes': len(codebook),\n",
        "            'quality_score': assessment_report['validation']['quality_score']\n",
        "        },\n",
        "        'codes': {}\n",
        "    }\n",
        "\n",
        "    for label, code in codebook.items():\n",
        "        json_export['codes'][label] = {\n",
        "            'definition': code.definition,\n",
        "            'inclusion': code.inclusion_criteria,\n",
        "            'exclusion': code.exclusion_criteria,\n",
        "            'examples': [ex['text'] for ex in code.examples],\n",
        "            'frequency': code.frequency,\n",
        "            'sources': code.source_documents\n",
        "        }\n",
        "\n",
        "    with open(f\"{Config.OUTPUT_PATH}codebook.json\", 'w') as f:\n",
        "        json.dump(json_export, f, indent=2)\n",
        "\n",
        "def export_to_markdown(codebook: Dict[str, CodeEntry],\n",
        "                      assessment_report: Dict,\n",
        "                      purpose_config: Dict):\n",
        "    \"\"\"Generate comprehensive markdown documentation\"\"\"\n",
        "\n",
        "    md_content = f\"\"\"# Codebook Documentation\n",
        "\n",
        "**Version**: {version_control.current_version}\n",
        "**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n",
        "**Purpose**: {purpose_config['purpose']}\n",
        "**Epistemological Stance**: {purpose_config['epistemological_stance']}\n",
        "\n",
        "## Overview\n",
        "\n",
        "This codebook was developed through systematic extraction from {len(set().union(*[code.source_documents for code in codebook.values()]))} source documents using a {Config.CODING_STRATEGY} coding approach.\n",
        "\n",
        "### Statistics\n",
        "- **Total Codes**: {len(codebook)}\n",
        "- **Average Frequency**: {np.mean([code.frequency for code in codebook.values()]):.1f}\n",
        "- **Conceptual Distinctness**: {assessment_report['reliability'].get('average_distinctness', 'N/A')}\n",
        "\n",
        "## Code Definitions\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    # Sort codes alphabetically\n",
        "    for label in sorted(codebook.keys()):\n",
        "        code = codebook[label]\n",
        "\n",
        "        md_content += f\"\"\"### {label}\n",
        "\n",
        "**Definition**: {code.definition}\n",
        "\n",
        "**Frequency**: {code.frequency} occurrences in {len(code.source_documents)} documents\n",
        "\n",
        "**When to use this code**:\n",
        "\"\"\"\n",
        "        for criterion in code.inclusion_criteria:\n",
        "            md_content += f\"- {criterion}\\n\"\n",
        "\n",
        "        md_content += \"\\n**When NOT to use this code**:\\n\"\n",
        "        for criterion in code.exclusion_criteria:\n",
        "            md_content += f\"- {criterion}\\n\"\n",
        "\n",
        "        md_content += \"\\n**Example applications**:\\n\\n\"\n",
        "        for i, example in enumerate(code.examples[:2], 1):\n",
        "            md_content += f'{i}. \"{example[\"text\"][:200]}...\" (*{example[\"source\"]}*)\\n\\n'\n",
        "\n",
        "        if code.notes:\n",
        "            md_content += \"**Notes**:\\n\"\n",
        "            for note in code.notes[-2:]:  # Last 2 notes\n",
        "                md_content += f\"- {note['date'][:10]}: {note['note']}\\n\"\n",
        "\n",
        "        md_content += \"\\n---\\n\\n\"\n",
        "\n",
        "    # Add changelog\n",
        "    md_content += \"## Version History\\n\\n\"\n",
        "    for entry in version_control.changelog[-5:]:  # Last 5 changes\n",
        "        md_content += f\"- **v{entry['version']}** ({entry['date'][:10]}): {entry['changes']}\\n\"\n",
        "\n",
        "    with open(f\"{Config.OUTPUT_PATH}codebook_documentation.md\", 'w') as f:\n",
        "        f.write(md_content)\n",
        "\n",
        "def export_to_atlas_format(codebook: Dict[str, CodeEntry]):\n",
        "    \"\"\"Export in ATLAS.ti compatible format\"\"\"\n",
        "    # Simplified XML format for ATLAS.ti\n",
        "    atlas_export = []\n",
        "    for label, code in codebook.items():\n",
        "        atlas_export.append({\n",
        "            'name': label,\n",
        "            'comment': code.definition,\n",
        "            'examples': [ex['text'] for ex in code.examples]\n",
        "        })\n",
        "\n",
        "    with open(f\"{Config.OUTPUT_PATH}codebook_atlas.json\", 'w') as f:\n",
        "        json.dump(atlas_export, f, indent=2)\n",
        "\n",
        "def export_to_nvivo_format(codebook: Dict[str, CodeEntry]):\n",
        "    \"\"\"Export in NVivo compatible format\"\"\"\n",
        "    # Simplified format for NVivo\n",
        "    nvivo_export = []\n",
        "    for label, code in codebook.items():\n",
        "        nvivo_export.append({\n",
        "            'Name': label,\n",
        "            'Description': code.definition,\n",
        "            'Files': ', '.join(code.source_documents)\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(nvivo_export)\n",
        "    df.to_csv(f\"{Config.OUTPUT_PATH}codebook_nvivo.csv\", index=False)"
      ],
      "metadata": {
        "id": "2VhoXGRAtcdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quality Report Generation"
      ],
      "metadata": {
        "id": "I410nD41te96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This block generates comprehensive quality reports\n",
        "\n",
        "def generate_quality_report(codebook: Dict[str, CodeEntry],\n",
        "                          assessment_report: Dict,\n",
        "                          extraction_log: List):\n",
        "    \"\"\"Generate comprehensive quality assurance report\"\"\"\n",
        "\n",
        "    report = {\n",
        "        'metadata': {\n",
        "            'version': version_control.current_version,\n",
        "            'generated': datetime.now().isoformat(),\n",
        "            'total_codes': len(codebook)\n",
        "        },\n",
        "        'quality_metrics': {\n",
        "            'overall_quality': assessment_report['validation']['quality_score'],\n",
        "            'conceptual_distinctness': assessment_report['reliability']['average_distinctness'],\n",
        "            'validation_issues': assessment_report['validation']['summary']\n",
        "        },\n",
        "        'extraction_summary': {\n",
        "            'total_extractions': len(extraction_log),\n",
        "            'documents_processed': len(set(e['document'] for e in extraction_log))\n",
        "        },\n",
        "        'recommendations': []\n",
        "    }\n",
        "\n",
        "    # Generate recommendations\n",
        "    if assessment_report['validation']['summary']['missing_definitions'] > 0:\n",
        "        report['recommendations'].append(\n",
        "            \"Add definitions to all codes before finalizing\"\n",
        "        )\n",
        "\n",
        "    if assessment_report['reliability']['average_distinctness'] < 0.8:\n",
        "        report['recommendations'].append(\n",
        "            \"Review overlapping codes for potential mergers\"\n",
        "        )\n",
        "\n",
        "    with open(f\"{Config.OUTPUT_PATH}quality_report.json\", 'w') as f:\n",
        "        json.dump(report, f, indent=2)\n",
        "\n",
        "def create_usage_guidelines(codebook: Dict[str, CodeEntry], purpose_config: Dict):\n",
        "    \"\"\"Create guidelines for using the codebook\"\"\"\n",
        "\n",
        "    guidelines = f\"\"\"# Codebook Usage Guidelines\n",
        "\n",
        "## Purpose\n",
        "{purpose_config['purpose']}\n",
        "\n",
        "## How to Apply These Codes\n",
        "\n",
        "1. **Read the full definition** before applying any code\n",
        "2. **Check inclusion criteria** - the text must meet these conditions\n",
        "3. **Check exclusion criteria** - if any apply, do not use the code\n",
        "4. **Reference the examples** when uncertain\n",
        "5. **Document edge cases** in your coding notes\n",
        "\n",
        "## Code Application Rules\n",
        "\n",
        "- Codes are conceptually mutually exclusive\n",
        "- Multiple codes may be applied to the same text segment if justified\n",
        "- When in doubt, refer to the examples provided\n",
        "- Record rationale for difficult coding decisions\n",
        "\n",
        "## Quality Checks\n",
        "\n",
        "- Aim for consistency across coders\n",
        "- Regular team meetings to discuss edge cases\n",
        "- Update coding notes for future reference\n",
        "- Version control any modifications\n",
        "\n",
        "## Contact\n",
        "For questions about code definitions or applications, consult the codebook documentation.\n",
        "\"\"\"\n",
        "\n",
        "    with open(f\"{Config.OUTPUT_PATH}usage_guidelines.md\", 'w') as f:\n",
        "        f.write(guidelines)"
      ],
      "metadata": {
        "id": "VnKQ5i_MtiUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Pipeline Execution"
      ],
      "metadata": {
        "id": "SRybfXmJ_7cO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the main execution pipeline that orchestrates the entire codebook development process\n",
        "\n",
        "def develop_codebook_pipeline():\n",
        "    \"\"\"\n",
        "    Main pipeline following the 8-step best practice guide\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"=== Codebook Development System ===\")\n",
        "    print(\"Following methodological best practices\\n\")\n",
        "\n",
        "    # Check if documents are uploaded\n",
        "    if 'uploaded_documents' not in globals() or not uploaded_documents:\n",
        "        print(\"\\nNo documents found. Please run the file upload cell above first!\")\n",
        "        return\n",
        "\n",
        "    # Step 1: Define purpose and scope\n",
        "    print(\"Step 1: Defining codebook purpose and scope...\")\n",
        "    purpose_config = define_codebook_purpose()\n",
        "    print(f\"Purpose: {purpose_config['purpose']}\")\n",
        "    print(f\"Epistemological stance: {purpose_config['epistemological_stance']}\")\n",
        "\n",
        "    # Step 2: Analyze document types\n",
        "    print(\"\\nStep 2: Analyzing uploaded documents...\")\n",
        "    document_analysis = analyze_document_types(uploaded_documents)\n",
        "    print(f\"Analyzed {len(document_analysis)} documents\")\n",
        "\n",
        "    # Save initial version\n",
        "    version_control.save_version({}, \"Initial setup - document analysis complete\")\n",
        "\n",
        "    # Step 3: Extract initial codes\n",
        "    print(\"\\nStep 3: Building initial code set...\")\n",
        "    initial_codebook, extraction_log = extract_initial_codes(\n",
        "        uploaded_documents,\n",
        "        Config.CODING_STRATEGY\n",
        "    )\n",
        "    print(f\"Extracted {len(initial_codebook)} initial codes\")\n",
        "\n",
        "    # Save version after initial extraction\n",
        "    version_control.increment_version(\"minor\")\n",
        "    version_control.save_version(initial_codebook, \"Initial code extraction complete\")\n",
        "\n",
        "    # Step 4: Refine and assess reliability\n",
        "    print(\"\\nStep 4: Training codes and assessing reliability...\")\n",
        "    refined_codebook, assessment_report = refine_and_assess_reliability(initial_codebook)\n",
        "    print(f\"Refined to {len(refined_codebook)} codes\")\n",
        "    print(f\"Quality score: {assessment_report['validation']['quality_score']:.2f}\")\n",
        "\n",
        "    # Step 5: Finalize and freeze\n",
        "    if assessment_report['validation']['quality_score'] >= 0.7:\n",
        "        print(\"\\nStep 5: Freezing codebook (quality threshold met)\")\n",
        "        version_control.increment_version(\"major\")\n",
        "        version_control.save_version(refined_codebook, \"Codebook frozen - ready for use\")\n",
        "    else:\n",
        "        print(\"\\nStep 5: Codebook needs improvement before freezing\")\n",
        "        print(\"Issues to address:\")\n",
        "        for issue_type, count in assessment_report['validation']['summary'].items():\n",
        "            if count > 0:\n",
        "                print(f\"  - {issue_type}: {count} codes\")\n",
        "\n",
        "    # Step 6: Export in multiple formats\n",
        "    print(\"\\nStep 6: Formatting for human and machine readability...\")\n",
        "    export_codebook_formats(refined_codebook, assessment_report, purpose_config)\n",
        "\n",
        "    # Step 7: Generate quality report\n",
        "    print(\"\\nStep 7: Generating quality assurance report...\")\n",
        "    generate_quality_report(refined_codebook, assessment_report, extraction_log)\n",
        "\n",
        "    # Step 8: Create usage guidelines\n",
        "    print(\"\\nStep 8: Creating usage guidelines...\")\n",
        "    create_usage_guidelines(refined_codebook, purpose_config)\n",
        "\n",
        "    print(\"\\n=== Codebook Development Complete ===\")\n",
        "    print(f\"Version: {version_control.current_version}\")\n",
        "    print(f\"Total codes: {len(refined_codebook)}\")\n",
        "    print(f\"Quality score: {assessment_report['validation']['quality_score']:.2f}\")\n",
        "    print(f\"\\nOutputs saved to: {Config.OUTPUT_PATH}\")\n",
        "\n",
        "    return refined_codebook, assessment_report\n",
        "\n",
        "# Run the pipeline\n",
        "print(\"Ready to run codebook development!\")\n",
        "print(\"To start, execute: develop_codebook_pipeline()\")"
      ],
      "metadata": {
        "id": "0Ambj8db_9P2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the Codebook Development\n"
      ],
      "metadata": {
        "id": "hLFISr5IAAGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute this cell to run the complete codebook development process\n",
        "develop_codebook_pipeline()"
      ],
      "metadata": {
        "id": "QDn-Kog_AByN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}